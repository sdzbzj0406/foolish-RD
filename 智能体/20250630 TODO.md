
1.      ai项目中的embedding向量检索的原理是什么，如何保证检索的准确性

2.      function call如何解析用户的意图

3.      如何实现模型的对话记忆功能，比如使用队列，还是堆，原理是什么

4.      文本怎么导入的向量知识库，切割的依据是什么

5.      对话记忆功能是所有的数据都保存吗，超出最大限度怎么办，prompt会改变吗

6.      非阻塞式响应式怎么实现的，引入什么依赖

7.      项目是基于什么协议的，和https什么区别

8.      前端有参与吗

9.      Zset是redis的什么结构，如何实现的

10.   Lua脚本使用的场景，作用

11.   讲讲乐观锁是什么，锁是什么，在什么场景使用了乐观锁

12.   全局唯一id是如何实现的

13.   压测是否做过

14.   单精度和双精度的区别

15.   Tcp的七层网络模型

手撕环节

1.      Sql查找

2.      多线程打印

3.      单例模式

4.      复原ip地址

算法干货

1.      看过哪些论文？

2.      过拟合和欠拟合的区别，如何解决

3.      优化算法的比较：sgd，adam，rmsprop

4.      梯度消失和梯度爆炸的原因和解决方法

5.      Batch normalization的作用和原理

6.      Transform的结构和工作原理

7.      Self-attention机制的计算过程和复杂度分析

8.      归一化方法的区别，layernorm，batchnorm

9.      常见激活函数的优缺点

10.   大模型训练的并行策略，数据并行，模型并行

11.   Llm的kv缓存机制

12.   大模型推理优化的常见方法

13.   Lora，adapter等参数高效微调的方法原理

14.   Leetcode中等、困难题目

15.   实现transformer中的self-attention，实现简单的语言模型训练过程

16.   大数组topk的多种解法和复杂度分析

17.   设计一个分布式训练框架的关键考虑点

18.   如何优化大模型的推理服务延迟和吞吐量

19.   模型量化部署的实践方案

20.   Pytorch的深度使用经验

21.   Deepseed和megatron的分布式训练框架的了解

22.   Cuda编程和性能优化经验