agent开发知识：
1. 什么是LLM agent，核心组成部分？llm+planning+memory+tools如何协同工作？
2. 记忆流memory stream的机制和长期任务的作用
3. 任务分解？task decomposition？列举分解方法，cot，tot，got
4. 如何通过思维链提升agent的推理能力
5. 如何解释agent的planning过程，如何动态调整规划
6. agent的感知-行动循环，perception-action loop如何实现
7. agent在复杂任务中如何平衡探索和扩展（exploration vs exploitation）
8. 什么是涌现能力，如何通过规模扩大产出新能力
9. agent的工具机制，如何与外部API集成
10. agent在实时场景下的响应延迟优化
11. 如何实际agent的奖励模型？reward model，需要和基座模型一致吗
12. agent的复读机问题的成因与缓解策略
13. 多模态agent的技术挑战，文本-图像-动作的协同

transform理论知识：
1. 介绍transform模型的核心原理和自注意力机制的作用
2. 多头注意力机制的设计动机与优势，举例说明不同头学习到的特征差异
3. q和k矩阵为什么使用不同的权重生成？打破对称性如何提升模型的表达能力
4. 计算注意力时为何选择点积而非加法，点积在捕捉向量相似度上的优势
5. softmax为何对注意力分数进行缩放？scaled，如何通过qurd_k缓解梯度消失问题
6. 如何处理变长序列中的padding部分，mask操作的具体实现方法
7. 位置编码positional encoding的作用，正弦、余弦编码公式的数学意义
8. transform中残差连接redisidual connection的作用和实现方式
9. 为何使用layernorm而不是batchnorm，layernorm在序列数据处理的优势
10. 前馈神经网络FNN的结构设计和激活函数的选择relugelu
11. 解释encode和decode的交互机制，decode如何利用encode的输出
12. decode自注意力和encode的自注意力的核心区别，比如mask机制
13. transform的并行化体现在哪里，decode端如何实现并行化？
14. wordpiece与bpe分词算法在transform中的应用场景
15. 模型输入embedding为何要乘以\（sqrtfd_model\）,梯度稳定性设计？
16. transform在训练中的学习率预热的策略和作用
17. dropout在transform中的应用位置和测试的注意事项
18. 如何用过kv cache技术优化推理显存占用
19. transform的输入长度限制及突破方法，比如分块、活动窗口
20. 如何通过flashattention优化长文本处理的注意力计算效率
21. 解释pageattention的原理和显存碎片化问题的解决方案
22. 动态量化和静态量化的区别和适用场景
23. 模型蒸馏的原理和如何压缩模型来保持性能
24. 混合精度训练amp的实现方法和对训练速度的影响
25. 如何总共deepspeed的zero优化器加速分布式训练

微调：
1. 如果要实现全参数微调，需要多少显存，怎么计算？
2. sft之后llm会变傻，为什么？
3. sft指令微调数据如何构建
4. 领域模型continue pretrain数据如何选取，领域数据训练后，通用能力有所下降，如何缓解
5. 领域模型如何在预训练过程中学习到更多的知识？
6. sft操作是基座模型是选择chat还是base，为什么
7. 领域模型微调对数据和指令的输入格式要求
8. 领域模型微调如何构建评测集
9. 模型模型微调对词表的扩增是否是必要的
10. 如何训练自己的大模型
11. 预训练和微调哪个阶段注入的知识
12. 如果让模型学习某个领域的知识，是在预训练还是微调
13. 预训练和sft的区别是什么
14. 多轮对话的任务如何进行微调
15. 微调大模型的建议
16. 微调大模型时，如果batch size太小或太大，有什么影响
17. 微调大模型时，优化器如何选择
18. 哪些因素会影响内存占用






















