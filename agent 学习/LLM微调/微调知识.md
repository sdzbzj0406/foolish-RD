# 🔧 大模型微调（Finetuning）学习笔记

---

## 1. 全参数微调需要多少显存？怎么估算？

全参数微调需加载模型参数、优化器状态、前向缓存，显存需求大。

### 粗略估算公式：
\[
\text{显存} ≈ 3 × \text{参数量} × \text{精度} + \text{中间激活} + \text{优化器状态}
\]

- 以一个 70B 模型为例（float16）：
  - 模型参数：70B × 2B = ~140GB
  - Optimizer 状态 + Gradients = ×2–3倍
  - 总显存需求：>400GB（需多卡并行）

---

## 2. 为什么 SFT 之后模型会变“傻”？

### 原因：
- **指令分布单一**：多为短指令+固定格式回复，缺少推理多样性
- **覆盖训练**：新数据过度“覆盖”通用能力
- **过拟合风格**：学习了固定语言模式，损失泛化能力

> 缓解方式：保留高质量原始数据、加入多样化任务、多任务指令融合

---

## 3. SFT 指令微调数据如何构建？

### 关键要素：
- **任务类型**：问答、摘要、归纳、多轮对话等
- **格式规范**：统一 prompt / response 格式，如：
  ```json
  {
    "instruction": "请总结以下文章",
    "input": "原文内容……",
    "output": "总结内容……"
  }
```
### 数据来源：

- 开源数据集（Alpaca、OpenAssistant）
    
- 自建：结构化转指令、知识图谱转问答
    
- 增强方法：改写、扩展、多语言版本

---

## 4. 领域 Continue Pretrain 的数据选择与通用能力下降问题

### 数据选取策略：

- 来源：学术论文、行业报告、领域知识库
    
- 清洗：去除乱码、重复、低质量内容
    
- 样本构成：文本长度、复杂度与通用语料保持一致
    

### 通用能力下降的原因：

- 语料偏移过大，模型“忘记”原有能力
    

### 缓解策略：

- Mix 多任务训练：50% 通用 + 50% 领域数据
    
- 使用 Low-rank Adapter（如 LoRA）避免覆盖全参数
    
- 使用少量通用数据持续 regularization
    

---

## 5. 如何让模型在预训练中学到更多领域知识？

- **构造方式**：
    
    - 高质量、覆盖面广的领域语料
        
    - 多任务形式预训练（分类、填空、排序等混合）
        
    - 使用 MLM/Causal LM 等目标训练
        
- **训练技巧**：
    
    - 增大 batch size 保留梯度稳定
        
    - 使用 RoPE/ALiBi 保持长序列建模能力
        

---

## 6. SFT 时基座模型用 Chat 还是 Base？

|类型|特点|适用场景|
|---|---|---|
|**Base**|仅完成预训练，无指令理解能力|适合纯任务微调（如分类）|
|**Chat（已指令调优）**|具备对话/指令理解能力|推荐作为SFT基座（省资源、效果好）|

> 一般建议基于 Chat 模型微调，以继承其通用对话能力

---

## 7. 领域模型微调的数据/指令格式要求

- 保持一致的指令格式（Instruction + Input + Response）
    
- 示例：
    
    shell
    
    复制编辑
    
    `### 指令：请将以下临床诊断结果总结 ### 输入：病历文本... ### 回答：该患者主要表现为...`
    

> 指令需贴近真实使用场景，控制长度、复杂度，确保数据分布合理

---

## 8. 领域模型评测集如何构建？

### 策略：

- 手工设计少量高质量任务（Gold Set）
    
- 自动从真实使用场景中采样
    
- 类型覆盖：问答、推理、摘要、知识检索等
    

### 评测指标：

- **BLEU/ROUGE**：文本生成
    
- **EM/F1**：抽取类任务
    
- **人评（人工打分）**：真实性、专业性、语义质量
    

---

## 9. 微调时是否需要扩充词表？

- 如果输入数据中包含大量 OOV（领域术语、英文缩写等），则**推荐扩词表**
    
- 不扩词表时会出现碎片 token，影响表示能力
    

> 注意：扩充词表需重新初始化Embedding层，影响原模型稳定性

---

## 10. 如何训练自己的大模型？

训练完整 LLM 包括：

- **预训练**：采集+清洗大规模语料，使用 Causal LM 或 MLM
    
- **SFT**：构建指令微调集提升任务表现
    
- **Alignment（对齐）**：如 RLHF/DPO，提升人类偏好能力
    
- **部署优化**：量化、蒸馏、KV Cache、剪枝
    

---

## 11. 知识注入发生在哪个阶段？

|阶段|注入类型|示例|
|---|---|---|
|**预训练**|基础知识（语言、常识、世界知识）|Wiki、C4|
|**微调/SFT**|任务知识、交互格式|指令、对话、领域问答|
|**继续预训练**|专业知识|医学、法律、金融文本|

---

## 12. 注入领域知识：预训练 or 微调？

- **微调注重风格、格式、行为**
    
- **预训练注重知识吸收、语言分布**
    

> 若目标是“让模型理解领域语言并做决策”，建议优先领域 continue pretrain，再进行指令微调。

---

## 13. 预训练 vs SFT：核心区别

|比较项|预训练|SFT|
|---|---|---|
|数据来源|通用文本|人类指令-响应对|
|模型目标|学习语言与知识|学习任务格式、行为模式|
|任务形式|无监督 / 自监督|监督微调|
|训练目标|LM Loss / MLM|CrossEntropy / DPO Loss|

---

## 14. 多轮对话微调的构建方式

- 使用历史多轮对话构建完整上下文
    
- 示例格式：
    
    复制编辑
    
    `用户：你好 助手：你好，有什么可以帮您？ 用户：我想订机票 助手：请问出发地和目的地是哪里？`
    

> 需注意上下文截断、对话角色标注、QA交替清晰

---

## 15. 微调大模型的实践建议

- 优先使用LoRA / QLoRA降低成本
    
- 多样化任务融合，避免过拟合单一任务
    
- 添加少量通用指令作为对齐辅助
    
- 微调步数不宜过多（1~3 epoch），防止灾难性遗忘
    

---

## 16. Batch Size 设置对微调的影响

|Batch Size|影响|
|---|---|
|太小（<4）|梯度震荡、不稳定，需降低学习率|
|太大（>512）|容易欠拟合、内存爆炸，训练慢|
|推荐值|32～128 + 梯度累积|

> 可通过 gradient accumulation 模拟大 batch

---

## 17. 微调时优化器选择

- **AdamW**：大模型微调默认选项，带L2正则
    
- **Lion**：Meta提出，更快收敛
    
- **Adafactor**：节省内存，适合大模型多卡
    

---

## 18. 影响显存占用的关键因素

- 模型参数量（参数规模）
    
- 激活缓存（forward cache）
    
- Batch Size / 序列长度
    
- Optimizer 状态（AdamW 比 SGD 大）
    
- Precision（FP16/FP32）
    
- 是否开启 KV Cache
    
- Checkpointing、Gradient Accumulation
    

---

## 📌 推荐微调技术路线图

1. 数据构建（指令 + 领域知识）
    
2. 选择基座模型（Chat / Base）
    
3. 使用 QLoRA + PEFT 实现参数高效微调
    
4. 构建评测集 + 自动评估指标
    
5. 使用多轮数据增强交互稳定性
    
6. 导出模型 + KV Cache 推理部署